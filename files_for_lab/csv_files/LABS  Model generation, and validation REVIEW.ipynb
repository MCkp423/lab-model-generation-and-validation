{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d912008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5428b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('marketing_customer_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4dbe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer</th>\n",
       "      <th>State</th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Response</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Education</th>\n",
       "      <th>Effective To Date</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>...</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Number of Policies</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Renew Offer Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Total Claim Amount</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Vehicle Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BU79786</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2763.519279</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/24/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>56274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>384.811147</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QZ44356</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6979.535903</td>\n",
       "      <td>No</td>\n",
       "      <td>Extended</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1/31/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer3</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1131.464935</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI49188</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>12887.431650</td>\n",
       "      <td>No</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/19/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>48767</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>566.472247</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WW63253</td>\n",
       "      <td>California</td>\n",
       "      <td>7645.861827</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>1/20/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>529.881344</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HB64268</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2813.692575</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/3/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>43836</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L1</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>138.130879</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9129</th>\n",
       "      <td>LA72316</td>\n",
       "      <td>California</td>\n",
       "      <td>23405.987980</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/10/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>71941</td>\n",
       "      <td>...</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L1</td>\n",
       "      <td>Offer2</td>\n",
       "      <td>Web</td>\n",
       "      <td>198.234764</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9130</th>\n",
       "      <td>PK87824</td>\n",
       "      <td>California</td>\n",
       "      <td>3096.511217</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>2/12/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>21604</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Branch</td>\n",
       "      <td>379.200000</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9131</th>\n",
       "      <td>TD14365</td>\n",
       "      <td>California</td>\n",
       "      <td>8163.890428</td>\n",
       "      <td>No</td>\n",
       "      <td>Extended</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>2/6/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Branch</td>\n",
       "      <td>790.784983</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9132</th>\n",
       "      <td>UP19263</td>\n",
       "      <td>California</td>\n",
       "      <td>7524.442436</td>\n",
       "      <td>No</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>2/3/11</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>21941</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L2</td>\n",
       "      <td>Offer3</td>\n",
       "      <td>Branch</td>\n",
       "      <td>691.200000</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>Y167826</td>\n",
       "      <td>California</td>\n",
       "      <td>2611.836866</td>\n",
       "      <td>No</td>\n",
       "      <td>Extended</td>\n",
       "      <td>College</td>\n",
       "      <td>2/14/11</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L3</td>\n",
       "      <td>Offer4</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>369.600000</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9134 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Customer       State  Customer Lifetime Value Response  Coverage  \\\n",
       "0     BU79786  Washington              2763.519279       No     Basic   \n",
       "1     QZ44356     Arizona              6979.535903       No  Extended   \n",
       "2     AI49188      Nevada             12887.431650       No   Premium   \n",
       "3     WW63253  California              7645.861827       No     Basic   \n",
       "4     HB64268  Washington              2813.692575       No     Basic   \n",
       "...       ...         ...                      ...      ...       ...   \n",
       "9129  LA72316  California             23405.987980       No     Basic   \n",
       "9130  PK87824  California              3096.511217      Yes  Extended   \n",
       "9131  TD14365  California              8163.890428       No  Extended   \n",
       "9132  UP19263  California              7524.442436       No  Extended   \n",
       "9133  Y167826  California              2611.836866       No  Extended   \n",
       "\n",
       "     Education Effective To Date EmploymentStatus Gender  Income  ...  \\\n",
       "0     Bachelor           2/24/11         Employed      F   56274  ...   \n",
       "1     Bachelor           1/31/11       Unemployed      F       0  ...   \n",
       "2     Bachelor           2/19/11         Employed      F   48767  ...   \n",
       "3     Bachelor           1/20/11       Unemployed      M       0  ...   \n",
       "4     Bachelor            2/3/11         Employed      M   43836  ...   \n",
       "...        ...               ...              ...    ...     ...  ...   \n",
       "9129  Bachelor           2/10/11         Employed      M   71941  ...   \n",
       "9130   College           2/12/11         Employed      F   21604  ...   \n",
       "9131  Bachelor            2/6/11       Unemployed      M       0  ...   \n",
       "9132   College            2/3/11         Employed      M   21941  ...   \n",
       "9133   College           2/14/11       Unemployed      M       0  ...   \n",
       "\n",
       "     Months Since Policy Inception Number of Open Complaints  \\\n",
       "0                                5                         0   \n",
       "1                               42                         0   \n",
       "2                               38                         0   \n",
       "3                               65                         0   \n",
       "4                               44                         0   \n",
       "...                            ...                       ...   \n",
       "9129                            89                         0   \n",
       "9130                            28                         0   \n",
       "9131                            37                         3   \n",
       "9132                             3                         0   \n",
       "9133                            90                         0   \n",
       "\n",
       "      Number of Policies     Policy Type        Policy  Renew Offer Type  \\\n",
       "0                      1  Corporate Auto  Corporate L3            Offer1   \n",
       "1                      8   Personal Auto   Personal L3            Offer3   \n",
       "2                      2   Personal Auto   Personal L3            Offer1   \n",
       "3                      7  Corporate Auto  Corporate L2            Offer1   \n",
       "4                      1   Personal Auto   Personal L1            Offer1   \n",
       "...                  ...             ...           ...               ...   \n",
       "9129                   2   Personal Auto   Personal L1            Offer2   \n",
       "9130                   1  Corporate Auto  Corporate L3            Offer1   \n",
       "9131                   2  Corporate Auto  Corporate L2            Offer1   \n",
       "9132                   3   Personal Auto   Personal L2            Offer3   \n",
       "9133                   1  Corporate Auto  Corporate L3            Offer4   \n",
       "\n",
       "      Sales Channel Total Claim Amount  Vehicle Class Vehicle Size  \n",
       "0             Agent         384.811147   Two-Door Car      Medsize  \n",
       "1             Agent        1131.464935  Four-Door Car      Medsize  \n",
       "2             Agent         566.472247   Two-Door Car      Medsize  \n",
       "3       Call Center         529.881344            SUV      Medsize  \n",
       "4             Agent         138.130879  Four-Door Car      Medsize  \n",
       "...             ...                ...            ...          ...  \n",
       "9129            Web         198.234764  Four-Door Car      Medsize  \n",
       "9130         Branch         379.200000  Four-Door Car      Medsize  \n",
       "9131         Branch         790.784983  Four-Door Car      Medsize  \n",
       "9132         Branch         691.200000  Four-Door Car        Large  \n",
       "9133    Call Center         369.600000   Two-Door Car      Medsize  \n",
       "\n",
       "[9134 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f7fdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns= df.columns.str.lower()\n",
    "df.columns= df.columns.str.replace(' ', '_', regex= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8266073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Select the columns which are correlated with `total_claim_amount` and don't suffer from multicollinearity (see the previous lab)\n",
    "#- Remove outliers\n",
    "#- X-y split. (define which column you want to predict, and which ones you will use to make the prediction)\n",
    "#- Use the [Train-test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) to create the Train, and Test sets (make sure to set the `random_state` option to any integer number of your choice).\n",
    "#- Use the [pd.DataFrame()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) function to create new Pandas DataFrames from the X_train, and X_test Numpy arrays obtained in the previous step (make sure to use the `columns=` option to set the columns names to `X.columns`).\n",
    "#- Split the `X_train` Pandas DataFrame into two: `numerical`, and `categorical` using `df.select_dtypes()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d71f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3faa76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns= ['customer_lifetime_value', 'income', 'monthly_premium_auto', 'total_claim_amount']\n",
    "df_selected= df[selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf8d3255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing outliers: (9134, 4)\n",
      "After removing outliers: (7847, 4)\n"
     ]
    }
   ],
   "source": [
    "Q1= df_selected.quantile(0.25)\n",
    "Q3= df_selected.quantile(0.75)\n",
    "IQR= Q3 - Q1\n",
    "\n",
    "df_no_outliers = df_selected[~((df_selected < (Q1 - 1.5 * IQR)) | (df_selected > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(\"Before removing outliers:\", df_selected.shape)\n",
    "print(\"After removing outliers:\", df_no_outliers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e0d330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (6277, 3)\n",
      "X_test shape: (1570, 3)\n",
      "y_train shape: (6277,)\n",
      "y_test shape: (1570,)\n"
     ]
    }
   ],
   "source": [
    "X = df_no_outliers.drop('total_claim_amount', axis=1)\n",
    "y = df_no_outliers['total_claim_amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.2, random_state= 42)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d23bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#- If you need to transform any column, Train your transformers and/or scalers all the `numerical` columns using the `.fit()` **only in the Train** set (only one transformer/scaler for all the columns, check [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer), and [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) using the `.transform()` \n",
    "#- Save all your transformers/scalers right after the `.fit()` using `pickle` using the code shown below:\n",
    " # ```Python\n",
    "  #import os\n",
    "  \n",
    "  #path = \"transformers/\"\n",
    "  # Check whether the specified path exists or not\n",
    "  #isExist = os.path.exists(path)\n",
    "  #if not isExist:\n",
    "   #   # Create a new directory because it does not exist\n",
    "    #  os.makedirs(path)\n",
    "    # print(\"The new directory is created!\")\n",
    " \n",
    " # filename = \"filename.pkl\" # Use a descriptive name for your scaler/transformer but keep the \".pkl\" file extension\n",
    "  #with open(path+filename, \"wb\") as file:\n",
    "   # pickle.dump(variable, file) # Replace \"variable\" with the name of the variable that contains your transformer\n",
    "  #```\n",
    "#- If you used a transformer/scaler in the previous step, create new Pandas DataFrames from the Numpy arrays generated by the `.transform()` using the `pd.DataFrame()` function as you did earlier with the Numpy arrays generated by the `train_test_split()` function.\n",
    "#- Transform the `categorical` columns into numbers using a:\n",
    " # - [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) for categorical **nominal** columns. (again **only use the `.fit()` in the Train set**, but the .`transform()` in the Train and the Test sets)\n",
    "  #- Remember to save all your transformers/scalers right after the `.fit()` using `pickle` using the code shown below:\n",
    "   # ```Python\n",
    "    #path = \"encoders/\"\n",
    "    ## Check whether the specified path exists or not\n",
    "    #isExist = os.path.exists(path)\n",
    "    #if not isExist:\n",
    "      # Create a new directory because it does not exist\n",
    "     # os.makedirs(path)\n",
    "      #print(\"The new directory is created!\")\n",
    " \n",
    "    #filename = \"filename.pkl\" # use a descriptive name for your encoder but keep the \".pkl\" file extension\n",
    "    #with open(path+filename, \"wb\") as file:\n",
    "     #  pickle.dump(variable, file) # Replace \"variable\" with the name of the variable that contains your transformer\n",
    "    #```\n",
    "  #- Use `.replace()` to cast into numbers any categorical **ordinal** column replacing each label with a number that: respects the order of the labels and the relative \"distance\"\n",
    "#- Concat `numerical_transformer` and `categorical_transfomed` DataFrames using `pd.concat()`.\n",
    "#- Apply another MinMaxScaler to the concatenated DataFrame.\n",
    "#- Remember to save all your MinMaxScaler right after the `.fit()` using `pickle` using the code shown below:\n",
    " #   ```Python\n",
    "  #  path = \"scalers/\"\n",
    "   # # Check whether the specified path exists or not\n",
    "   # isExist = os.path.exists(path)\n",
    "   # if not isExist:\n",
    "      # Create a new directory because it does not exist\n",
    "    #  os.makedirs(path)\n",
    "     # print(\"The new directory is created!\")\n",
    " \n",
    "   # filename = \"filename.pkl\" # use a descriptive name for your encoder but keep the \".pkl\" file extension\n",
    "   # with open(path+filename, \"wb\") as file:\n",
    "    #   pickle.dump(variable, file) # Replace \"variable\" with the name of the variable that contains your transformer\n",
    "    #```\n",
    "#- Apply linear regression to the Pandas DataFrame obtained in the previous step using [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)\n",
    "#- Remember to save your linear model right after the `.fit()` using `pickle` using the code shown below:\n",
    " # ```Python\n",
    "  #    path = \"models/\"\n",
    "   #   # Check whether the specified path exists or not\n",
    "    #  isExist = os.path.exists(path)\n",
    "     # if not isExist:\n",
    "      #  # Create a new directory because it does not exist\n",
    "       # os.makedirs(path)\n",
    "       # print(\"The new directory is created!\")\n",
    " \n",
    "       #filename = \"filename.pkl\" # use a descriptive name for your encoder but keep the \".pkl\" file extension\n",
    "       #with open(path+filename, \"wb\") as file:\n",
    "        #  pickle.dump(variable, file) # Replace \"variable\" with the name of the variable that contains your transformer\n",
    "   # ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f9d52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "numerical_cols = X_train_df.select_dtypes(include=['int', 'float']).columns\n",
    "numerical = X_train_df[numerical_cols]\n",
    "\n",
    "power_transformer = PowerTransformer()\n",
    "numerical_transformed = power_transformer.fit_transform(numerical)\n",
    "\n",
    "path = \"transformers/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "with open(os.path.join(path, \"power_transformer.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(power_transformer, file)\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "numerical_transformed = minmax_scaler.fit_transform(numerical_transformed)\n",
    "\n",
    "with open(os.path.join(path, \"minmax_scaler.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(minmax_scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1d4cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_cols = X_train_df.select_dtypes(include=['object']).columns\n",
    "categorical = X_train_df[categorical_cols]\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "categorical_transformed = onehot_encoder.fit_transform(categorical).toarray()\n",
    "\n",
    "path = \"encoders/\"\n",
    "os.makedirs(path, exist_ok=True)\n",
    "with open(os.path.join(path, \"onehot_encoder.pkl\"), \"wb\") as file:\n",
    "    pickle.dump(onehot_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f60e9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformed_df = pd.DataFrame(numerical_transformed, columns=numerical.columns)\n",
    "categorical_transformed_df = pd.DataFrame(categorical_transformed, columns=onehot_encoder.get_feature_names_out())\n",
    "\n",
    "X_transformed = pd.concat([numerical_transformed_df, categorical_transformed_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da87272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_transformed, y_train)\n",
    "\n",
    "models_dir = \"models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(models_dir, \"linear_model.pkl\")\n",
    "with open(model_path, \"wb\") as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "619a13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Validation\n",
    "\n",
    "#- Compute the following metrics for your Train and Test sets:\n",
    " # - [R2](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score).\n",
    " # - [MSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn-metrics-mean-squared-error).\n",
    " #- [RMSE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn-metrics-mean-squared-error)\n",
    " # - [MAE](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn-metrics-mean-absolute-error).\n",
    "\n",
    "#- Create a Pandas DataFrame to summarize the error metrics for the Train and Test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81a0ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Metric         Train          Test\n",
      "0     R2      0.344393 -2.922812e+09\n",
      "1    MSE  27514.329417  1.214950e+14\n",
      "2   RMSE    165.874439  1.102248e+07\n",
      "3    MAE    129.617465  8.636716e+06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Compute metrics\n",
    "train_predictions = model.predict(X_transformed)\n",
    "test_predictions = model.predict(X_test)  # Apply similar transformations to X_test\n",
    "\n",
    "train_r2 = r2_score(y_train, train_predictions)\n",
    "train_mse = mean_squared_error(y_train, train_predictions)\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "\n",
    "test_r2 = r2_score(y_test, test_predictions)\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "\n",
    "# Summarizing the metrics\n",
    "metrics_summary = pd.DataFrame({\n",
    "    'Metric': ['R2', 'MSE', 'RMSE', 'MAE'],\n",
    "    'Train': [train_r2, train_mse, train_rmse, train_mae],\n",
    "    'Test': [test_r2, test_mse, test_rmse, test_mae]\n",
    "})\n",
    "\n",
    "print(metrics_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98feb8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
